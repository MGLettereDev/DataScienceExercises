{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Análisis de Señales - Transformada de Fourier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Identificación de Notas Musicales con Audio Real"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Cargaremos una grabación de audio .wav (Notas musicales de una guitarra RE, MI, SOL)\n",
    "* Obtendremos la variación temporal de la señal de audio\n",
    "* Encontraremos la frecuencia dominante y la compararemos con los rangos de frecuencias de las notas musicales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reproducimos el sonido que vamos a cargar\n",
    "\n",
    "import winsound\n",
    "filename='rec_RE.wav'                                \n",
    "winsound.PlaySound(filename, winsound.SND_FILENAME)   \n",
    "\n",
    "# Leemos el archivo digital de audio del directorio\n",
    "\n",
    "import scipy.io.wavfile as waves\n",
    "samplerate, data = waves.read(filename)                       \n",
    "Audio_m = data[:,0]              \n",
    "\n",
    "# Tomamos la longitud de la señal\n",
    "\n",
    "L = len(Audio_m)                                      \n",
    "\n",
    "# Definimos un vector de tiempo de la misma longitud de la señal\n",
    "\n",
    "import numpy as np\n",
    "n = np.arange(0,L)/samplerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "plt.plot(n,Audio_m)\n",
    "plt.xlabel(\"Time(s)\")\n",
    "plt.ylabel(\"Amplitude\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculamos la Transformada de Fourier\n",
    "\n",
    "#%matplotlib notebook\n",
    "\n",
    "from scipy.fft import rfft, rfftfreq\n",
    "\n",
    "yf = rfft(Audio_m)\n",
    "xf = rfftfreq(L, 1 / samplerate)\n",
    "\n",
    "# Dibujamos el espectro de frecuencia del archivo de audio\n",
    "\n",
    "plt.plot(xf, np.abs(yf))\n",
    "plt.xlabel(\"Frequency (Hz)\")\n",
    "plt.ylabel(\"Amplitud\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.fft import fft, fftfreq, rfft, rfftfreq, irfft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tarea 1: Grafique el espectro de frecuencia de 0 a 5000 Hz.\n",
    "normalized_tone = np.int16((Audio_m/Audio_m.max())*32767)\n",
    "\n",
    "plt.plot(normalized_tone[:1000])\n",
    "plt.xlabel(\"Tiempo (s)\")\n",
    "plt.ylabel(\"Amplitude\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "yf = fft(normalized_tone)\n",
    "xf = fftfreq(L, 1 / samplerate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(xf, np.abs(yf))\n",
    "plt.xlabel(\"Frecuencia (Hz)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(xf, np.abs(yf))\n",
    "plt.xlabel(\"Frecuencia (Hz)\")\n",
    "plt.xlim([0, 5000])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tarea 2: Determine el espectro de frecuencia para la nota MI.\n",
    "\n",
    "filename='rec_MI.wav'                                \n",
    "winsound.PlaySound(filename, winsound.SND_FILENAME)   \n",
    "\n",
    "# Leemos el archivo digital de audio del directorio\n",
    "\n",
    "samplerate, data = waves.read(filename)                       \n",
    "Audio_m = data[:,0]              \n",
    "\n",
    "# Tomamos la longitud de la señal\n",
    "\n",
    "L = len(Audio_m)                                      \n",
    "\n",
    "# Definimos un vector de tiempo de la misma longitud de la señal\n",
    "\n",
    "n = np.arange(0,L)/samplerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(n,Audio_m)\n",
    "plt.xlabel(\"Time(s)\")\n",
    "plt.ylabel(\"Amplitude\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_tone = np.int16((Audio_m/Audio_m.max())*32767)\n",
    "\n",
    "plt.plot(normalized_tone[:1000])\n",
    "plt.xlabel(\"Tiempo (s)\")\n",
    "plt.ylabel(\"Amplitude\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "yf = fft(normalized_tone)\n",
    "xf = fftfreq(L, 1 / samplerate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(xf, np.abs(yf))\n",
    "plt.xlabel(\"Frecuencia (Hz)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(xf, np.abs(yf))\n",
    "plt.xlabel(\"Frecuencia (Hz)\")\n",
    "plt.xlim([0, 5000])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tarea 3: Determine el espectro de frecuencia para la nota SOL.\n",
    "filename='rec_SOL.wav'                                \n",
    "winsound.PlaySound(filename, winsound.SND_FILENAME)   \n",
    "\n",
    "# Leemos el archivo digital de audio del directorio\n",
    "\n",
    "samplerate, data = waves.read(filename)                       \n",
    "Audio_m = data[:,0]              \n",
    "\n",
    "# Tomamos la longitud de la señal\n",
    "\n",
    "L = len(Audio_m)                                      \n",
    "\n",
    "# Definimos un vector de tiempo de la misma longitud de la señal\n",
    "\n",
    "n = np.arange(0,L)/samplerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(n,Audio_m)\n",
    "plt.xlabel(\"Time(s)\")\n",
    "plt.ylabel(\"Amplitude\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_tone = np.int16((Audio_m/Audio_m.max())*32767)\n",
    "\n",
    "plt.plot(normalized_tone[:1000])\n",
    "plt.xlabel(\"Tiempo (s)\")\n",
    "plt.ylabel(\"Amplitude\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "yf = fft(normalized_tone)\n",
    "xf = fftfreq(L, 1 / samplerate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(xf, np.abs(yf))\n",
    "plt.xlabel(\"Frecuencia (Hz)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(xf, np.abs(yf))\n",
    "plt.xlabel(\"Frecuencia (Hz)\")\n",
    "plt.xlim([0, 5000])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Analisis Espectral en Tiempo Real Usando Entrada de Micrófono"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Instalaremos PyAudio para la adquicisión de audio en tiempo real\n",
    "* Leemos la señal del micrófono en paquetes de tamaño especificado por el parámetro FRAMES y con frecuencia Fs\n",
    "* Calculamos la FFT para cada paquete leido, mostramos la gráfica temporal y el espectro de la señal\n",
    "* Calculamos la Frecuencia Dominante para cada paquete leido\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: PyAudio in c:\\users\\estudiante\\appdata\\roaming\\python\\python311\\site-packages (0.2.13)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 23.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install PyAudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[Errno -9996] Invalid input device (no default output device)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Estudiante\\Downloads\\AnalisisSeniales_ML.ipynb Cell 27\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Estudiante/Downloads/AnalisisSeniales_ML.ipynb#X35sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m Fs \u001b[39m=\u001b[39m \u001b[39m44100\u001b[39m                                        \u001b[39m# Frecuencia de muestreo típica para audio\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Estudiante/Downloads/AnalisisSeniales_ML.ipynb#X35sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m p \u001b[39m=\u001b[39m pa\u001b[39m.\u001b[39mPyAudio()\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Estudiante/Downloads/AnalisisSeniales_ML.ipynb#X35sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m stream \u001b[39m=\u001b[39m p\u001b[39m.\u001b[39;49mopen(                                  \u001b[39m# Abrimos el canal de audio con los parámeteros de configuración\u001b[39;49;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Estudiante/Downloads/AnalisisSeniales_ML.ipynb#X35sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m     \u001b[39mformat\u001b[39;49m \u001b[39m=\u001b[39;49m FORMAT,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Estudiante/Downloads/AnalisisSeniales_ML.ipynb#X35sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m     channels \u001b[39m=\u001b[39;49m CHANNELS,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Estudiante/Downloads/AnalisisSeniales_ML.ipynb#X35sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m     rate \u001b[39m=\u001b[39;49m Fs,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Estudiante/Downloads/AnalisisSeniales_ML.ipynb#X35sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m     \u001b[39minput\u001b[39;49m\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Estudiante/Downloads/AnalisisSeniales_ML.ipynb#X35sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m     output\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Estudiante/Downloads/AnalisisSeniales_ML.ipynb#X35sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m     frames_per_buffer\u001b[39m=\u001b[39;49mFRAMES\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Estudiante/Downloads/AnalisisSeniales_ML.ipynb#X35sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m )\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Estudiante/Downloads/AnalisisSeniales_ML.ipynb#X35sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m \u001b[39m## Creamos una gráfica con 2 subplots y configuramos los ejes\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Estudiante/Downloads/AnalisisSeniales_ML.ipynb#X35sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m fig, (ax,ax1) \u001b[39m=\u001b[39m plt\u001b[39m.\u001b[39msubplots(\u001b[39m2\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pyaudio\\__init__.py:639\u001b[0m, in \u001b[0;36mPyAudio.open\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    631\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mopen\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m    632\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Opens a new stream.\u001b[39;00m\n\u001b[0;32m    633\u001b[0m \n\u001b[0;32m    634\u001b[0m \u001b[39m    See constructor for :py:func:`PyAudio.Stream.__init__` for parameter\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    637\u001b[0m \u001b[39m    :returns: A new :py:class:`PyAudio.Stream`\u001b[39;00m\n\u001b[0;32m    638\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 639\u001b[0m     stream \u001b[39m=\u001b[39m PyAudio\u001b[39m.\u001b[39;49mStream(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    640\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_streams\u001b[39m.\u001b[39madd(stream)\n\u001b[0;32m    641\u001b[0m     \u001b[39mreturn\u001b[39;00m stream\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pyaudio\\__init__.py:441\u001b[0m, in \u001b[0;36mPyAudio.Stream.__init__\u001b[1;34m(self, PA_manager, rate, channels, format, input, output, input_device_index, output_device_index, frames_per_buffer, start, input_host_api_specific_stream_info, output_host_api_specific_stream_info, stream_callback)\u001b[0m\n\u001b[0;32m    438\u001b[0m     arguments[\u001b[39m'\u001b[39m\u001b[39mstream_callback\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m stream_callback\n\u001b[0;32m    440\u001b[0m \u001b[39m# calling pa.open returns a stream object\u001b[39;00m\n\u001b[1;32m--> 441\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stream \u001b[39m=\u001b[39m pa\u001b[39m.\u001b[39;49mopen(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49marguments)\n\u001b[0;32m    443\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_input_latency \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stream\u001b[39m.\u001b[39minputLatency\n\u001b[0;32m    444\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output_latency \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stream\u001b[39m.\u001b[39moutputLatency\n",
      "\u001b[1;31mOSError\u001b[0m: [Errno -9996] Invalid input device (no default output device)"
     ]
    }
   ],
   "source": [
    "import matplotlib\n",
    "import pyaudio as pa \n",
    "import struct\n",
    "from scipy.fft import fft\n",
    "\n",
    "matplotlib.use('TkAgg')\n",
    "\n",
    "FRAMES = 1024*8                                   # Tamaño del paquete a procesar\n",
    "FORMAT = pa.paInt16                               # Formato de lectura INT 16 bits\n",
    "CHANNELS = 1\n",
    "Fs = 44100                                        # Frecuencia de muestreo típica para audio\n",
    "\n",
    "p = pa.PyAudio()\n",
    "\n",
    "stream = p.open(                                  # Abrimos el canal de audio con los parámeteros de configuración\n",
    "    format = FORMAT,\n",
    "    channels = CHANNELS,\n",
    "    rate = Fs,\n",
    "    input=True,\n",
    "    output=True,\n",
    "    frames_per_buffer=FRAMES\n",
    ")\n",
    "\n",
    "## Creamos una gráfica con 2 subplots y configuramos los ejes\n",
    "\n",
    "fig, (ax,ax1) = plt.subplots(2)\n",
    "\n",
    "x_audio = np.arange(0,FRAMES,1)\n",
    "x_fft = np.linspace(0, Fs, FRAMES)\n",
    "\n",
    "line, = ax.plot(x_audio, np.random.rand(FRAMES),'r')\n",
    "line_fft, = ax1.semilogx(x_fft, np.random.rand(FRAMES), 'b')\n",
    "\n",
    "ax.set_ylim(-32500,32500)\n",
    "ax.ser_xlim = (0,FRAMES)\n",
    "\n",
    "Fmin = 1\n",
    "Fmax = 5000\n",
    "ax1.set_xlim(Fmin,Fmax)\n",
    "\n",
    "fig.show()\n",
    "\n",
    "\n",
    "F = (Fs/FRAMES)*np.arange(0,FRAMES//2)                 # Creamos el vector de frecuencia para encontrar la frecuencia dominante\n",
    "\n",
    "while True:\n",
    "    \n",
    "    data = stream.read(FRAMES)                         # Leemos paquetes de longitud FRAMES\n",
    "    dataInt = struct.unpack(str(FRAMES) + 'h', data)   # Convertimos los datos que se encuentran empaquetados en bytes\n",
    "    \n",
    "    line.set_ydata(dataInt)                            # Asignamos los datos a la curva de la variación temporal\n",
    "    \n",
    "    M_gk = abs(fft(dataInt)/FRAMES)            # Calculamos la FFT y la Magnitud de la FFT del paqute de datos\n",
    "\n",
    "    \n",
    "    ax1.set_ylim(0,np.max(M_gk+10)) \n",
    "    line_fft.set_ydata(M_gk)                           # Asigmanos la Magnitud de la FFT a la curva del espectro \n",
    "    \n",
    "    M_gk = M_gk[0:FRAMES//2]                           # Tomamos la mitad del espectro para encontrar la Frecuencia Dominante\n",
    "    Posm = np.where(M_gk == np.max(M_gk))\n",
    "    F_fund = F[Posm]                                   # Encontramos la frecuencia que corresponde con el máximo de M_gk\n",
    "    \n",
    "    print(int(F_fund))                                 # Imprimimos el valor de la frecuencia dominante\n",
    "\n",
    "    fig.canvas.draw()\n",
    "    fig.canvas.flush_events()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Análisis espectral de la voz de una persona.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grabe un audio con su voz pronunciando la siguiente frase: \"Mi nombre es NOMBRE APELLIDO, tengo XX años, y estudio la carrera de Sistemas de Información\". Con este archivo digital de su voz, determine el espectro de frecuencia de su registro de voz. Recomendación, grabe en formato .wav."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tarea 4: Escriba su código aquí."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
